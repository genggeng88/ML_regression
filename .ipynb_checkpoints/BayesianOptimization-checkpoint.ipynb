{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edd9e5f",
   "metadata": {},
   "source": [
    "Bayesian optimization is a machine learning technique for optimizing expensive and black-box functions, where the function's underlying mathematical formula is unknown or difficult to evaluate, but it can be queried at various input points.\n",
    "\n",
    "The basic idea behind Bayesian optimization is to build a probabilistic surrogate model of the unknown objective function, called a \"surrogate model\" or \"response surface model\". This surrogate model is used to guide the search for the optimal input values. The surrogate model is constructed using a Bayesian framework that updates the model as new data points are observed. Specifically, the surrogate model uses a Gaussian process to model the distribution over the objective function, which allows it to capture the uncertainty in the predictions.\n",
    "\n",
    "The Bayesian optimization algorithm sequentially selects the next input point to evaluate by maximizing an acquisition function that trades off between exploration and exploitation. The acquisition function measures the expected improvement in the objective function value that would result from evaluating the function at a particular input point, given the current state of the surrogate model.\n",
    "\n",
    "By selecting input points that optimize the acquisition function and evaluating the objective function at those points, the surrogate model is updated, and the search for the optimal input values continues. The process continues until the maximum number of iterations is reached, or until convergence is achieved.\n",
    "\n",
    "Bayesian optimization has been successfully applied to a wide range of optimization problems in various domains, including machine learning, engineering, and scientific research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394581a",
   "metadata": {},
   "source": [
    "To perform Bayesian optimization, you typically need the following:\n",
    "\n",
    "An objective function to be optimized. This is the function that you want to find the maximum or minimum value of, and it should take as input one or more variables (also called hyperparameters) that you can adjust to influence the output of the function.\n",
    "\n",
    "A search space for the hyperparameters. This is the range of values that the hyperparameters can take on during the optimization process. The search space can be continuous, discrete, or a mix of both.\n",
    "\n",
    "An acquisition function. This is a function that determines which hyperparameter values to evaluate next based on previous evaluations. The acquisition function balances exploration (trying out new hyperparameter values) and exploitation (focusing on promising hyperparameter values).\n",
    "\n",
    "A surrogate model. This is a probabilistic model that approximates the objective function and is used to predict the performance of different hyperparameter values. The surrogate model is typically a Gaussian process.\n",
    "\n",
    "A method for optimizing the acquisition function. This involves finding the hyperparameter values that maximize the acquisition function, subject to the constraints of the search space.\n",
    "\n",
    "There are several Python packages that provide implementations of Bayesian optimization, such as scikit-optimize, BayesianOptimization, and GPyOpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d5e73f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All elements in list must be instances of <class 'skopt.space.space.Dimension'>, but found: [('x', Real(low=-10, high=10, prior='uniform', transform='identity')), ('y', Real(low=-10, high=10, prior='uniform', transform='identity'))]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ns/7q3hd22d3zj3rbv059dzhp540000gn/T/ipykernel_69438/993873851.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m ])\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Ensure all dimensions are correctly typed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mcheck_list_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# Ensure all dimensions have names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mcheck_list_types\u001b[0;34m(x, types)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"All elements in list must be instances of {}, but found: {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All elements in list must be instances of <class 'skopt.space.space.Dimension'>, but found: [('x', Real(low=-10, high=10, prior='uniform', transform='identity')), ('y', Real(low=-10, high=10, prior='uniform', transform='identity'))]"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the objective function to be optimized\n",
    "@use_named_args([\n",
    "    ('x', Real(-10, 10)),\n",
    "    ('y', Real(-10, 10))\n",
    "])\n",
    "def objective_function(x, y):\n",
    "    return np.sin(x) + np.cos(y)\n",
    "\n",
    "# Specify the search space\n",
    "dimensions = [('x', Real(-10, 10)), ('y', Real(-10, 10))]\n",
    "space = Space([Real(*dim) for dim in dimensions])\n",
    "#space = [Real(-10, 10, name='x'), Real(-10, 10, name='y')]\n",
    "\n",
    "# Run Bayesian optimization to find the optimal input values\n",
    "result = gp_minimize(objective_function, space, n_calls=20, random_state=42)\n",
    "\n",
    "# Print the optimal input values and corresponding objective function value\n",
    "print(\"Optimal input values: {}\".format(result.x))\n",
    "print(\"Optimal objective function value: {:.3f}\".format(result.fun))\n",
    "\n",
    "# Visualize the search process\n",
    "plt.plot(result.func_vals)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective function value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e86e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-87.55   \u001b[0m | \u001b[0m-2.509   \u001b[0m | \u001b[0m9.014    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-25.42   \u001b[0m | \u001b[95m4.64     \u001b[0m | \u001b[95m1.973    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-26.44   \u001b[0m | \u001b[0m4.759    \u001b[0m | \u001b[0m1.949    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m-2.492   \u001b[0m | \u001b[95m0.92     \u001b[0m | \u001b[95m-1.283   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-49.12   \u001b[0m | \u001b[0m-1.537   \u001b[0m | \u001b[0m-6.838   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/7q3hd22d3zj3rbv059dzhp540000gn/T/ipykernel_70639/180766967.py:18: DeprecationWarning: \n",
      "Passing acquisition function parameters or gaussian process parameters to maximize\n",
      "is no longer supported, and will cause an error in future releases. Instead,\n",
      "please use the \"set_gp_params\" method to set the gp params, and pass an instance\n",
      " of bayes_opt.util.UtilityFunction using the acquisition_function argument\n",
      "\n",
      "  optimizer.maximize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m6        \u001b[0m | \u001b[0m-6.546   \u001b[0m | \u001b[0m-2.523   \u001b[0m | \u001b[0m0.4244   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-101.0   \u001b[0m | \u001b[0m-10.0    \u001b[0m | \u001b[0m-1.008   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m-10.0    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m10.0     \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m-10.0    \u001b[0m | \u001b[0m-10.0    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m-10.0    \u001b[0m | \u001b[0m10.0     \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-10.71   \u001b[0m | \u001b[0m-0.4336  \u001b[0m | \u001b[0m3.244    \u001b[0m |\n",
      "=================================================\n",
      "{'target': -2.4923888767972917, 'params': {'x': 0.9199895185372754, 'y': -1.2829684963313963}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Define the objective function to be optimized\n",
    "def objective_function(x, y):\n",
    "    return -(x**2 + y**2)\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "pbounds = {'x': (-10, 10), 'y': (-10, 10)}\n",
    "\n",
    "# Define the Bayesian optimization object\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(\n",
    "    init_points=2,  # number of initial points to evaluate randomly\n",
    "    n_iter=10,  # number of iterations of optimization\n",
    "    acq='ei'  # acquisition function to use (expected improvement)\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters and objective function value found\n",
    "print(optimizer.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3883f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
