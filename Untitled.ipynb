{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b77db87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ns/7q3hd22d3zj3rbv059dzhp540000gn/T/ipykernel_32225/492227915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGaussianRegressionWithDerivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GaussianRegressionWithDerivatives():\n",
    "    def __init__(self, kernel=None, dd_kernel=None, sigma=1e-6):\n",
    "        self.kernel = kernel\n",
    "        self.dd_kernel = dd_kernel\n",
    "        self.sigma = sigma\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "    def fit(self, X, y, dy):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.dy = dy\n",
    "        # print('the shape of self.kernel(X, X) is: ' + str(self.kernel(X, X).shape))\n",
    "        self.K = self.kernel(X, X) + self.sigma**2 * np.eye(len(X))\n",
    "        # print('the shape of self.K is: ' + str(self.K.shape))\n",
    "        self.dK = self.dd_kernel(X, X) + self.sigma**2 * np.eye(len(X))\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "        self.dL = np.linalg.cholesky(self.dK)\n",
    "        # let alpha = inv(K) * y => K * alpha = y => L*L.T * alpha = y => alpha = solve(L.T, solve(L, y))\n",
    "        self.alpha = np.linalg.solve(self.L.T, np.linalg.solve(self.L, y))\n",
    "        self.dalpha = np.linalg.solve(self.dL.T, np.linalg.solve(self.dL, dy))\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, Xtest):\n",
    "\n",
    "        K_train_test = self.kernel(self.X, Xtest)\n",
    "        y_pred = K_train_test.T @ self.alpha\n",
    "\n",
    "        dK_train_test = self.dd_kernel(self.X, Xtest)\n",
    "        dy_pred = dK_train_test.T @ self.dalpha\n",
    "\n",
    "        # L*v = K => v = inv(L)*K => v.T * v = K.T * inv(L.T) * inv(L) * K = K.T * inv(L*L.T) * K\n",
    "        # v = cp.linalg.solve(self.L, K_train_test)\n",
    "        # cov = self.kernel(Xtest, Xtest) - v.T @ v\n",
    "        # std = cp.sqrt(cp.diag(cov))\n",
    "\n",
    "        # return mean, cov, std\n",
    "        \n",
    "        return y_pred, dy_pred\n",
    "\n",
    "def d_mu(x):\n",
    "    return 0 \n",
    "\n",
    "def RBF(x1, x2, length_scale=1.0):\n",
    "    diff_mat = x1[:, cp.newaxis] - x2\n",
    "    return np.exp(-0.5 * diff_mat ** 2 / length_scale ** 2)\n",
    "\n",
    "def d_RBF(x1, x2, length_scale=1.0):\n",
    "    diff_mat = x1[:, cp.newaxis] - x2\n",
    "    return diff_mat * cp.exp(-0.5 * diff_mat ** 2 / length_scale ** 2)\n",
    "\n",
    "def dd_RBF(x1, x2, length_scale=1.0):\n",
    "    diff_mat = x1[:, cp.newaxis] - x2\n",
    "    return (1 - diff_mat**2/length_scale**2)/length_scale**2 * cp.exp(-0.5 * diff_mat ** 2 / length_scale ** 2)\n",
    "\n",
    "\n",
    "X = cp.array(cp.random.uniform(-5, 5, size=(50,)))\n",
    "y = cp.array(cp.sin(X) + cp.random.normal(0, 0.1, size=(50,)))\n",
    "dy = cp.array(cp.cos(X))\n",
    "\n",
    "gr = GaussianRegressionWithDerivatives(RBF, dd_RBF)\n",
    "gr.fit(X,y,dy)\n",
    "\n",
    "# use the same data set as training, y_pred and dy_pred should be similar to y and dy\n",
    "y_pred, dy_pred = gr.predict(X)\n",
    "\n",
    "print('y is: \\n' + str(y[:10]))\n",
    "print('y_pred is: \\n' + str(y_pred[:10]))\n",
    "print('dy is: \\n' + str(dy[:10]))\n",
    "print('dy_pred: \\n' + str(dy_pred[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa59fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f441e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'panda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ns/7q3hd22d3zj3rbv059dzhp540000gn/T/ipykernel_32225/4002472836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpanda\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'panda'"
     ]
    }
   ],
   "source": [
    "import panda as pd\n",
    "\n",
    "url = \"test_data.csv\"\n",
    "dataset = pd.read_csv(url, spe=';')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5d2178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is: [2. 4. 6.]\n",
      "y_pred is: [2. 4. 6.]\n",
      "cov: \n",
      "[[1.00008890e-12 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00019992e-12 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00008890e-12]]\n",
      "std: [1.00004445e-06 1.00009996e-06 1.00004445e-06]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianRegressorCholesky:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.sigma = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y, sigma=1e-6):\n",
    "        self.sigma = sigma\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.K = self.kernel(X, X) + self.sigma**2 * np.eye(len(X))\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "        # let alpha = inv(K) * y => K * alpha = y => L*L.T * alpha = y => alpha = solve(L.T, solve(L, y))\n",
    "        self.alpha = np.linalg.solve(self.L.T, np.linalg.solve(self.L, y))\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        K_train_test = self.kernel(self.X, Xtest)\n",
    "        mean = K_train_test.T @ self.alpha\n",
    "\n",
    "        # L*v = K => v = inv(L)*K => v.T * v = K.T * inv(L.T) * inv(L) * K = K.T * inv(L*L.T) * K\n",
    "        v = np.linalg.solve(self.L, K_train_test)\n",
    "        cov = self.kernel(Xtest, Xtest) - v.T @ v\n",
    "        std = np.sqrt(np.diag(cov))\n",
    "\n",
    "        return mean, cov, std\n",
    "\n",
    "def rbf_kernel(X1, X2, length_scale=1.0):\n",
    "    np.atleast_2d(X1)\n",
    "    np.atleast_2d(X2)\n",
    "    s1 = X1.shape\n",
    "    s2 = X2.shape\n",
    "    \n",
    "    if (s1[1] != s2[1]):\n",
    "        print(\"ERROR! RBF input matices must have the same number of columns!\")\n",
    "        return\n",
    "\n",
    "    dists = np.sum((X1[:, np.newaxis] - X2) ** 2, axis=2)\n",
    "    return np.exp(-dists / (2 * length_scale ** 2))\n",
    "\n",
    "def mu(x):\n",
    "    n = x.shape[0]\n",
    "    return np.sum(x,axis=0) / n\n",
    "\n",
    "X1 = np.array([[1.,2.,3.],[3.,4.,5.],[5.,6.,7.]])\n",
    "y = np.array([2.,4.,6.])\n",
    "gr = GaussianRegressorCholesky(rbf_kernel)\n",
    "gr.fit(X1,y)\n",
    "\n",
    "# use the same data set as training, y_pred should be similar to y\n",
    "y_pred, cov, std = gr.predict(X1)\n",
    "\n",
    "print('y is: ' + str(y))\n",
    "print('y_pred is: ' + str(y_pred))\n",
    "print('cov: \\n' + str(cov))\n",
    "print('std: ' + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8901ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0,2],[1,3],[2,4],[3,5],[4,6],[5,7],[6,8],[7,9],[8,10],[9,11],[10,12]])\n",
    "y = np.array([4,10,20,34,52,74,100,130,164,202,244])\n",
    "dy = np.array([[0,4],[2,6],[4,8],[6,10],[8,12],[10,14],[12,16],[14,18],[16,20],[18,22],[20,24]])\n",
    "\n",
    "x_test = np.array([[0,2],[1,3],[2,4]])\n",
    "y_test = np.array([4,10,20])\n",
    "dy_test = np.array([[22,26],[24,28],[26,20],[28,32]])\n",
    "    \n",
    "print(mu(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b597b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is: [ 4 10 20]\n",
      "y_pred is: [ 4. 10. 20.]\n",
      "cov: \n",
      "[[1.00008890e-12 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00008890e-12 1.11022302e-16]\n",
      " [0.00000000e+00 1.11022302e-16 1.00008890e-12]]\n",
      "std: [1.00004445e-06 1.00004445e-06 1.00004445e-06]\n"
     ]
    }
   ],
   "source": [
    "gr = GaussianRegressorCholesky(rbf_kernel)\n",
    "gr.fit(x,y)\n",
    "\n",
    "# use the same data set as training, y_pred should be similar to y\n",
    "y_pred, cov, std = gr.predict(x_test)\n",
    "\n",
    "print('y is: ' + str(y_test))\n",
    "print('y_pred is: ' + str(y_pred))\n",
    "print('cov: \\n' + str(cov))\n",
    "print('std: ' + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e66b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is: [[205]\n",
      " [207]\n",
      " [209]\n",
      " [211]\n",
      " [213]\n",
      " [215]\n",
      " [217]\n",
      " [219]\n",
      " [221]\n",
      " [223]\n",
      " [225]\n",
      " [227]\n",
      " [229]\n",
      " [231]\n",
      " [233]\n",
      " [235]\n",
      " [237]\n",
      " [239]\n",
      " [241]]\n",
      "y_pred is: [[2.44595852e+01]\n",
      " [2.00156322e+00]\n",
      " [6.03943728e-02]\n",
      " [6.70758239e-04]\n",
      " [2.74100871e-06]\n",
      " [4.12081800e-09]\n",
      " [2.27913549e-12]\n",
      " [4.63730152e-16]\n",
      " [3.47110002e-20]\n",
      " [9.55817188e-25]\n",
      " [9.68251568e-30]\n",
      " [3.60833752e-35]\n",
      " [4.94688298e-41]\n",
      " [2.49494884e-47]\n",
      " [4.62910652e-54]\n",
      " [3.15964450e-61]\n",
      " [7.93386467e-69]\n",
      " [7.32886755e-77]\n",
      " [2.49054548e-85]]\n",
      "cov: \n",
      "[[9.68842797e-01 6.03851971e-01 1.35253024e-01 1.11080771e-02\n",
      "  3.35458862e-04 3.72664751e-06 1.52299766e-08 2.28973478e-11\n",
      "  1.26641655e-14 2.57675711e-18 1.92874985e-22 5.31109225e-27\n",
      "  5.38018616e-32 2.00500878e-37 2.74878501e-43 1.38634329e-49\n",
      "  2.57220937e-56 1.75568810e-63 4.40853133e-71]\n",
      " [6.03851971e-01 9.99768994e-01 6.06523558e-01 1.35335204e-01\n",
      "  1.11089962e-02 3.35462627e-04 3.72665317e-06 1.52299797e-08\n",
      "  2.28973485e-11 1.26641655e-14 2.57675711e-18 1.92874985e-22\n",
      "  5.31109225e-27 5.38018616e-32 2.00500878e-37 2.74878501e-43\n",
      "  1.38634329e-49 2.57220937e-56 1.75568810e-63]\n",
      " [1.35253024e-01 6.06523558e-01 9.99999782e-01 6.06530657e-01\n",
      "  1.35335283e-01 1.11089965e-02 3.35462628e-04 3.72665317e-06\n",
      "  1.52299797e-08 2.28973485e-11 1.26641655e-14 2.57675711e-18\n",
      "  1.92874985e-22 5.31109225e-27 5.38018616e-32 2.00500878e-37\n",
      "  2.74878501e-43 1.38634329e-49 2.57220937e-56]\n",
      " [1.11080771e-02 1.35335204e-01 6.06530657e-01 1.00000000e+00\n",
      "  6.06530660e-01 1.35335283e-01 1.11089965e-02 3.35462628e-04\n",
      "  3.72665317e-06 1.52299797e-08 2.28973485e-11 1.26641655e-14\n",
      "  2.57675711e-18 1.92874985e-22 5.31109225e-27 5.38018616e-32\n",
      "  2.00500878e-37 2.74878501e-43 1.38634329e-49]\n",
      " [3.35458862e-04 1.11089962e-02 1.35335283e-01 6.06530660e-01\n",
      "  1.00000000e+00 6.06530660e-01 1.35335283e-01 1.11089965e-02\n",
      "  3.35462628e-04 3.72665317e-06 1.52299797e-08 2.28973485e-11\n",
      "  1.26641655e-14 2.57675711e-18 1.92874985e-22 5.31109225e-27\n",
      "  5.38018616e-32 2.00500878e-37 2.74878501e-43]\n",
      " [3.72664751e-06 3.35462627e-04 1.11089965e-02 1.35335283e-01\n",
      "  6.06530660e-01 1.00000000e+00 6.06530660e-01 1.35335283e-01\n",
      "  1.11089965e-02 3.35462628e-04 3.72665317e-06 1.52299797e-08\n",
      "  2.28973485e-11 1.26641655e-14 2.57675711e-18 1.92874985e-22\n",
      "  5.31109225e-27 5.38018616e-32 2.00500878e-37]\n",
      " [1.52299766e-08 3.72665317e-06 3.35462628e-04 1.11089965e-02\n",
      "  1.35335283e-01 6.06530660e-01 1.00000000e+00 6.06530660e-01\n",
      "  1.35335283e-01 1.11089965e-02 3.35462628e-04 3.72665317e-06\n",
      "  1.52299797e-08 2.28973485e-11 1.26641655e-14 2.57675711e-18\n",
      "  1.92874985e-22 5.31109225e-27 5.38018616e-32]\n",
      " [2.28973478e-11 1.52299797e-08 3.72665317e-06 3.35462628e-04\n",
      "  1.11089965e-02 1.35335283e-01 6.06530660e-01 1.00000000e+00\n",
      "  6.06530660e-01 1.35335283e-01 1.11089965e-02 3.35462628e-04\n",
      "  3.72665317e-06 1.52299797e-08 2.28973485e-11 1.26641655e-14\n",
      "  2.57675711e-18 1.92874985e-22 5.31109225e-27]\n",
      " [1.26641655e-14 2.28973485e-11 1.52299797e-08 3.72665317e-06\n",
      "  3.35462628e-04 1.11089965e-02 1.35335283e-01 6.06530660e-01\n",
      "  1.00000000e+00 6.06530660e-01 1.35335283e-01 1.11089965e-02\n",
      "  3.35462628e-04 3.72665317e-06 1.52299797e-08 2.28973485e-11\n",
      "  1.26641655e-14 2.57675711e-18 1.92874985e-22]\n",
      " [2.57675711e-18 1.26641655e-14 2.28973485e-11 1.52299797e-08\n",
      "  3.72665317e-06 3.35462628e-04 1.11089965e-02 1.35335283e-01\n",
      "  6.06530660e-01 1.00000000e+00 6.06530660e-01 1.35335283e-01\n",
      "  1.11089965e-02 3.35462628e-04 3.72665317e-06 1.52299797e-08\n",
      "  2.28973485e-11 1.26641655e-14 2.57675711e-18]\n",
      " [1.92874985e-22 2.57675711e-18 1.26641655e-14 2.28973485e-11\n",
      "  1.52299797e-08 3.72665317e-06 3.35462628e-04 1.11089965e-02\n",
      "  1.35335283e-01 6.06530660e-01 1.00000000e+00 6.06530660e-01\n",
      "  1.35335283e-01 1.11089965e-02 3.35462628e-04 3.72665317e-06\n",
      "  1.52299797e-08 2.28973485e-11 1.26641655e-14]\n",
      " [5.31109225e-27 1.92874985e-22 2.57675711e-18 1.26641655e-14\n",
      "  2.28973485e-11 1.52299797e-08 3.72665317e-06 3.35462628e-04\n",
      "  1.11089965e-02 1.35335283e-01 6.06530660e-01 1.00000000e+00\n",
      "  6.06530660e-01 1.35335283e-01 1.11089965e-02 3.35462628e-04\n",
      "  3.72665317e-06 1.52299797e-08 2.28973485e-11]\n",
      " [5.38018616e-32 5.31109225e-27 1.92874985e-22 2.57675711e-18\n",
      "  1.26641655e-14 2.28973485e-11 1.52299797e-08 3.72665317e-06\n",
      "  3.35462628e-04 1.11089965e-02 1.35335283e-01 6.06530660e-01\n",
      "  1.00000000e+00 6.06530660e-01 1.35335283e-01 1.11089965e-02\n",
      "  3.35462628e-04 3.72665317e-06 1.52299797e-08]\n",
      " [2.00500878e-37 5.38018616e-32 5.31109225e-27 1.92874985e-22\n",
      "  2.57675711e-18 1.26641655e-14 2.28973485e-11 1.52299797e-08\n",
      "  3.72665317e-06 3.35462628e-04 1.11089965e-02 1.35335283e-01\n",
      "  6.06530660e-01 1.00000000e+00 6.06530660e-01 1.35335283e-01\n",
      "  1.11089965e-02 3.35462628e-04 3.72665317e-06]\n",
      " [2.74878501e-43 2.00500878e-37 5.38018616e-32 5.31109225e-27\n",
      "  1.92874985e-22 2.57675711e-18 1.26641655e-14 2.28973485e-11\n",
      "  1.52299797e-08 3.72665317e-06 3.35462628e-04 1.11089965e-02\n",
      "  1.35335283e-01 6.06530660e-01 1.00000000e+00 6.06530660e-01\n",
      "  1.35335283e-01 1.11089965e-02 3.35462628e-04]\n",
      " [1.38634329e-49 2.74878501e-43 2.00500878e-37 5.38018616e-32\n",
      "  5.31109225e-27 1.92874985e-22 2.57675711e-18 1.26641655e-14\n",
      "  2.28973485e-11 1.52299797e-08 3.72665317e-06 3.35462628e-04\n",
      "  1.11089965e-02 1.35335283e-01 6.06530660e-01 1.00000000e+00\n",
      "  6.06530660e-01 1.35335283e-01 1.11089965e-02]\n",
      " [2.57220937e-56 1.38634329e-49 2.74878501e-43 2.00500878e-37\n",
      "  5.38018616e-32 5.31109225e-27 1.92874985e-22 2.57675711e-18\n",
      "  1.26641655e-14 2.28973485e-11 1.52299797e-08 3.72665317e-06\n",
      "  3.35462628e-04 1.11089965e-02 1.35335283e-01 6.06530660e-01\n",
      "  1.00000000e+00 6.06530660e-01 1.35335283e-01]\n",
      " [1.75568810e-63 2.57220937e-56 1.38634329e-49 2.74878501e-43\n",
      "  2.00500878e-37 5.38018616e-32 5.31109225e-27 1.92874985e-22\n",
      "  2.57675711e-18 1.26641655e-14 2.28973485e-11 1.52299797e-08\n",
      "  3.72665317e-06 3.35462628e-04 1.11089965e-02 1.35335283e-01\n",
      "  6.06530660e-01 1.00000000e+00 6.06530660e-01]\n",
      " [4.40853133e-71 1.75568810e-63 2.57220937e-56 1.38634329e-49\n",
      "  2.74878501e-43 2.00500878e-37 5.38018616e-32 5.31109225e-27\n",
      "  1.92874985e-22 2.57675711e-18 1.26641655e-14 2.28973485e-11\n",
      "  1.52299797e-08 3.72665317e-06 3.35462628e-04 1.11089965e-02\n",
      "  1.35335283e-01 6.06530660e-01 1.00000000e+00]]\n",
      "std: [0.98429812 0.99988449 0.99999989 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(-100,100,1).reshape(200,1)\n",
    "y = np.array(2*x + 3).reshape(200,1)\n",
    "\n",
    "x_test = np.arange(101,120,1).reshape(19,1)\n",
    "y_test = np.array(2*x_test + 3).reshape(19,1)\n",
    "\n",
    "gr = GaussianRegressorCholesky(rbf_kernel)\n",
    "gr.fit(x,y)\n",
    "\n",
    "# use the same data set as training, y_pred should be similar to y\n",
    "y_pred, cov, std = gr.predict(x_test)\n",
    "\n",
    "print('y is: ' + str(y_test))\n",
    "print('y_pred is: ' + str(y_pred))\n",
    "print('cov: \\n' + str(cov))\n",
    "print('std: ' + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff2d1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean is: [[112.36265161]\n",
      " [101.01217995]\n",
      " [100.03054683]\n",
      " [100.00033929]\n",
      " [100.00000139]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]\n",
      " [100.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianRegressor:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.sigma = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y, sigma=1e-6):\n",
    "        self.sigma = sigma\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        K = self.kernel(self.X, self.X) + self.sigma * np.eye(len(self.X))\n",
    "        K_train_test = self.kernel(self.X, Xtest)\n",
    "        #K_star = self.kernel(Xtest, self.X)\n",
    "        K_test_test = self.kernel(Xtest, Xtest) + self.sigma * np.eye(len(Xtest))\n",
    "        \n",
    "        #mean = K_train_test.T @ cp.linalg.inv(K) @ self.y\n",
    "\n",
    "        # mu(x_train) and mu(x_test) are not strictly required\n",
    "        mean = mu(Xtest) + K_train_test.T @ np.linalg.inv(K) @ (self.y - mu(self.X))\n",
    "        # mean = K_train_test.T @ np.linalg.inv(K) @ (self.y)\n",
    "\n",
    "        # returned cov represents the uncertainty associated with the predicted mean at each test point\n",
    "        #cov = K_test_test - K_train_test.T @ np.linalg.inv(K) @ K_train_test\n",
    "        #std = np.sqrt(np.diag(cov))\n",
    "\n",
    "        return mean\n",
    "\n",
    "# Define the RBF kernel\n",
    "# now X1 and X2 are m1-n and m2-n dimensional matrix\n",
    "# X1 and X2 have the same column number n which denotes the number of featrues\n",
    "# X1 and X2 have different first dimension m1 and m2 which denote number of data point\n",
    "def rbf_kernel(X1, X2, length_scale=1.0):\n",
    "    np.atleast_2d(X1)\n",
    "    np.atleast_2d(X2)\n",
    "    s1 = X1.shape\n",
    "    s2 = X2.shape\n",
    "    \n",
    "    if (s1[1] != s2[1]):\n",
    "        print(\"ERROR! RBF input matices must have the same number of columns!\")\n",
    "        return\n",
    "\n",
    "    dists = np.sum((X1[:, np.newaxis] - X2) ** 2, axis=2)\n",
    "    return np.exp(-dists / (2 * length_scale ** 2))\n",
    "\n",
    "def mu(x):\n",
    "    '''\n",
    "    m = x.shape[0]\n",
    "    n = x.shape[1]\n",
    "    return (np.sum(x,axis=1) / n).reshape(m,1)\n",
    "    '''\n",
    "    return 2*x\n",
    "\n",
    "x = np.arange(-100,100,1).reshape(200,1)\n",
    "y = np.array(2*x + 3).reshape(200,1)\n",
    "\n",
    "x_test = np.arange(101,120,1).reshape(19,1)\n",
    "y_test = np.array(2*x_test + 3).reshape(19,1)\n",
    "\n",
    "gr = GaussianRegressor(rbf_kernel)\n",
    "gr.fit(x,y)\n",
    "\n",
    "# use the same data set as training, y_pred should be similar to y\n",
    "#y_pred = gr.predict(x)\n",
    "\n",
    "#print('y is: ' + str(y_test))\n",
    "#print('y_pred is: ' + str(y_pred))\n",
    "\n",
    "\n",
    "k_x_x = rbf_kernel(x, x)\n",
    "k_t_x = rbf_kernel(x_test, x)\n",
    "\n",
    "#print(k_x_x)\n",
    "#print(k_t_x)\n",
    "\n",
    "mean = mu(x_test) + k_t_x @ np.linalg.inv(k_x_x) @ (y - mu(x))\n",
    "    \n",
    "print('mean is: '+ str(mean))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce759a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.60653066 0.13533528 ... 0.         0.         0.        ]\n",
      " [0.60653066 1.         0.60653066 ... 0.         0.         0.        ]\n",
      " [0.13533528 0.60653066 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.60653066 0.13533528]\n",
      " [0.         0.         0.         ... 0.60653066 1.         0.60653066]\n",
      " [0.         0.         0.         ... 0.13533528 0.60653066 1.        ]]\n",
      "[[1.         0.60653066 0.13533528 ... 0.         0.         0.        ]\n",
      " [0.60653066 1.         0.60653066 ... 0.         0.         0.        ]\n",
      " [0.13533528 0.60653066 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.60653066 0.13533528]\n",
      " [0.         0.         0.         ... 0.60653066 1.         0.60653066]\n",
      " [0.         0.         0.         ... 0.13533528 0.60653066 1.        ]]\n",
      "[[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 3.35462628e-004\n",
      "  1.11089965e-002 1.35335283e-001]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 3.72665317e-006\n",
      "  3.35462628e-004 1.11089965e-002]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.52299797e-008\n",
      "  3.72665317e-006 3.35462628e-004]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.38389653e-087\n",
      "  4.07235863e-079 4.40853133e-071]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.73008221e-096\n",
      "  1.38389653e-087 4.07235863e-079]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 7.95674389e-106\n",
      "  1.73008221e-096 1.38389653e-087]]\n",
      "[[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 3.35462628e-004\n",
      "  1.11089965e-002 1.35335283e-001]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 3.72665317e-006\n",
      "  3.35462628e-004 1.11089965e-002]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.52299797e-008\n",
      "  3.72665317e-006 3.35462628e-004]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.38389653e-087\n",
      "  4.07235863e-079 4.40853133e-071]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.73008221e-096\n",
      "  1.38389653e-087 4.07235863e-079]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 7.95674389e-106\n",
      "  1.73008221e-096 1.38389653e-087]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "kernel = RBF(length_scale=1.0)\n",
    "\n",
    "x = np.arange(-100,100,1).reshape(200,1)\n",
    "y = np.array(2*x + 3).reshape(200,1)\n",
    "\n",
    "x_test = np.arange(101,120,1).reshape(19,1)\n",
    "y_test = np.array(2*x_test + 3).reshape(19,1)\n",
    "\n",
    "k_x_x = kernel(x, x)\n",
    "k_t_x = kernel(x_test, x)\n",
    "\n",
    "k_x_x2 = rbf_kernel(x, x)\n",
    "k_t_x2 = rbf_kernel(x_test, x)\n",
    "\n",
    "print(k_x_x)\n",
    "print(k_x_x2)\n",
    "print(k_t_x)\n",
    "print(k_t_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d282528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-196.99974572]\n",
      " [-194.99979944]\n",
      " [-192.99984719]\n",
      " [-190.99988941]\n",
      " [-188.99992651]\n",
      " [-186.9999589 ]\n",
      " [-184.99998694]\n",
      " [-183.00001098]\n",
      " [-181.00003135]\n",
      " [-179.00004839]\n",
      " [-177.00006236]\n",
      " [-175.00007358]\n",
      " [-173.00008229]\n",
      " [-171.00008875]\n",
      " [-169.00009317]\n",
      " [-167.0000958 ]\n",
      " [-165.00009683]\n",
      " [-163.00009644]\n",
      " [-161.00009483]\n",
      " [-159.00009214]\n",
      " [-157.00008854]\n",
      " [-155.00008416]\n",
      " [-153.00007915]\n",
      " [-151.00007361]\n",
      " [-149.00006767]\n",
      " [-147.00006141]\n",
      " [-145.00005494]\n",
      " [-143.00004833]\n",
      " [-141.00004166]\n",
      " [-139.00003501]\n",
      " [-137.00002842]\n",
      " [-135.00002196]\n",
      " [-133.00001567]\n",
      " [-131.0000096 ]\n",
      " [-129.00000377]\n",
      " [-126.99999822]\n",
      " [-124.99999298]\n",
      " [-122.99998806]\n",
      " [-120.99998348]\n",
      " [-118.99997927]\n",
      " [-116.99997541]\n",
      " [-114.99997192]\n",
      " [-112.9999688 ]\n",
      " [-110.99996604]\n",
      " [-108.99996365]\n",
      " [-106.99996162]\n",
      " [-104.99995994]\n",
      " [-102.9999586 ]\n",
      " [-100.99995759]\n",
      " [ -98.99995689]\n",
      " [ -96.99995649]\n",
      " [ -94.99995638]\n",
      " [ -92.99995653]\n",
      " [ -90.99995693]\n",
      " [ -88.99995757]\n",
      " [ -86.99995841]\n",
      " [ -84.99995946]\n",
      " [ -82.99996068]\n",
      " [ -80.99996205]\n",
      " [ -78.99996356]\n",
      " [ -76.99996518]\n",
      " [ -74.99996691]\n",
      " [ -72.99996872]\n",
      " [ -70.9999706 ]\n",
      " [ -68.99997251]\n",
      " [ -66.99997445]\n",
      " [ -64.99997642]\n",
      " [ -62.99997839]\n",
      " [ -60.99998033]\n",
      " [ -58.99998225]\n",
      " [ -56.99998413]\n",
      " [ -54.99998596]\n",
      " [ -52.99998772]\n",
      " [ -50.99998941]\n",
      " [ -48.99999102]\n",
      " [ -46.99999255]\n",
      " [ -44.99999398]\n",
      " [ -42.9999953 ]\n",
      " [ -40.99999653]\n",
      " [ -38.99999764]\n",
      " [ -36.99999865]\n",
      " [ -34.99999955]\n",
      " [ -33.00000033]\n",
      " [ -31.00000099]\n",
      " [ -29.00000155]\n",
      " [ -27.000002  ]\n",
      " [ -25.00000235]\n",
      " [ -23.00000259]\n",
      " [ -21.00000273]\n",
      " [ -19.00000278]\n",
      " [ -17.00000275]\n",
      " [ -15.00000263]\n",
      " [ -13.00000245]\n",
      " [ -11.00000219]\n",
      " [  -9.00000189]\n",
      " [  -7.00000153]\n",
      " [  -5.00000114]\n",
      " [  -3.00000071]\n",
      " [  -1.00000025]\n",
      " [   1.0000002 ]\n",
      " [   3.00000067]\n",
      " [   5.00000113]\n",
      " [   7.00000157]\n",
      " [   9.00000198]\n",
      " [  11.00000237]\n",
      " [  13.00000271]\n",
      " [  15.00000299]\n",
      " [  17.00000322]\n",
      " [  19.00000337]\n",
      " [  21.00000345]\n",
      " [  23.00000345]\n",
      " [  25.00000337]\n",
      " [  27.00000318]\n",
      " [  29.0000029 ]\n",
      " [  31.00000251]\n",
      " [  33.00000201]\n",
      " [  35.0000014 ]\n",
      " [  37.00000068]\n",
      " [  38.99999985]\n",
      " [  40.9999989 ]\n",
      " [  42.99999784]\n",
      " [  44.99999666]\n",
      " [  46.99999538]\n",
      " [  48.99999399]\n",
      " [  50.9999925 ]\n",
      " [  52.99999092]\n",
      " [  54.99998925]\n",
      " [  56.9999875 ]\n",
      " [  58.99998567]\n",
      " [  60.99998379]\n",
      " [  62.99998185]\n",
      " [  64.99997988]\n",
      " [  66.99997787]\n",
      " [  68.99997586]\n",
      " [  70.99997385]\n",
      " [  72.99997185]\n",
      " [  74.99996989]\n",
      " [  76.99996798]\n",
      " [  78.99996613]\n",
      " [  80.99996437]\n",
      " [  82.99996272]\n",
      " [  84.99996118]\n",
      " [  86.99995978]\n",
      " [  88.99995855]\n",
      " [  90.9999575 ]\n",
      " [  92.99995664]\n",
      " [  94.99995601]\n",
      " [  96.9999556 ]\n",
      " [  98.99995546]\n",
      " [ 100.99995559]\n",
      " [ 102.99995601]\n",
      " [ 104.99995672]\n",
      " [ 106.99995777]\n",
      " [ 108.99995914]\n",
      " [ 110.99996086]\n",
      " [ 112.99996294]\n",
      " [ 114.99996537]\n",
      " [ 116.99996819]\n",
      " [ 118.99997137]\n",
      " [ 120.99997492]\n",
      " [ 122.99997884]\n",
      " [ 124.99998314]\n",
      " [ 126.99998779]\n",
      " [ 128.99999279]\n",
      " [ 130.99999812]\n",
      " [ 133.00000375]\n",
      " [ 135.00000966]\n",
      " [ 137.00001583]\n",
      " [ 139.00002221]\n",
      " [ 141.00002876]\n",
      " [ 143.00003544]\n",
      " [ 145.00004219]\n",
      " [ 147.00004894]\n",
      " [ 149.00005563]\n",
      " [ 151.00006219]\n",
      " [ 153.00006853]\n",
      " [ 155.00007455]\n",
      " [ 157.00008015]\n",
      " [ 159.00008522]\n",
      " [ 161.00008965]\n",
      " [ 163.00009328]\n",
      " [ 165.000096  ]\n",
      " [ 167.00009763]\n",
      " [ 169.000098  ]\n",
      " [ 171.00009696]\n",
      " [ 173.0000943 ]\n",
      " [ 175.00008981]\n",
      " [ 177.00008327]\n",
      " [ 179.00007445]\n",
      " [ 181.00006311]\n",
      " [ 183.00004896]\n",
      " [ 185.00003174]\n",
      " [ 187.00001114]\n",
      " [ 188.99998684]\n",
      " [ 190.9999585 ]\n",
      " [ 192.99992578]\n",
      " [ 194.99988829]\n",
      " [ 196.99984563]\n",
      " [ 198.9997974 ]\n",
      " [ 200.99974315]]\n",
      "[[204.99961471]\n",
      " [206.99953953]\n",
      " [208.99945634]\n",
      " [210.99936456]\n",
      " [212.99926363]\n",
      " [214.99915292]\n",
      " [216.99903179]\n",
      " [218.99889956]\n",
      " [220.99875553]\n",
      " [222.99859898]\n",
      " [224.99842913]\n",
      " [226.99824518]\n",
      " [228.99804631]\n",
      " [230.99783164]\n",
      " [232.99760029]\n",
      " [234.99735131]\n",
      " [236.99708372]\n",
      " [238.99679651]\n",
      " [240.99648863]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingeng/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/qingeng/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/qingeng/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-100,100,1).reshape(200,1)\n",
    "y = np.array(2*x + 3).reshape(200,1)\n",
    "\n",
    "x_test = np.arange(101,120,1).reshape(19,1)\n",
    "y_test = np.array(2*x_test + 3).reshape(19,1)\n",
    "\n",
    "# use a combined kernel\n",
    "kernel = ConstantKernel(1.0) + ConstantKernel(1.0) * RBF(10) + WhiteKernel(5)\n",
    "model = GaussianProcessRegressor(kernel=kernel)\n",
    "model.fit(x, y)\n",
    "y_pred_tr, y_pred_tr_std = model.predict(x, return_std=True)\n",
    "y_pred_te, y_pred_te_std = model.predict(x_test, return_std=True)\n",
    "\n",
    "print(y_pred_tr)\n",
    "print(y_pred_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1909741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
